{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e6272f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6ced384c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a26c79f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "order = [\n",
    "    'Insufficient_Weight',\n",
    "    'Normal_Weight',\n",
    "    'Overweight_Level_I',\n",
    "    'Overweight_Level_II',\n",
    "    'Obesity_Type_I',\n",
    "    'Obesity_Type_II',\n",
    "    'Obesity_Type_III'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "24d9a2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def broad_category(cat):\n",
    "    if cat == 'Insufficient_Weight':\n",
    "        return 'Underweight'\n",
    "    elif cat == 'Normal_Weight':\n",
    "        return 'Normal'\n",
    "    elif cat.startswith('Overweight'):\n",
    "        return 'Overweight'\n",
    "    else:\n",
    "        return 'Obese'\n",
    "\n",
    "df['BroadCategory'] = df['WeightCategory'].apply(broad_category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5cc741aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BMI'] = df['Weight'] / (df['Height'] ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "262f1bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "male_df = df[df['Gender'].str.lower() == 'male'].reset_index(drop=True)\n",
    "female_df = df[df['Gender'].str.lower() == 'female'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2f1fa6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "male_df.drop(['id', 'Gender'], axis=1, inplace=True)\n",
    "female_df.drop(['id', 'Gender'], axis=1, inplace=True)\n",
    "df.drop(['id', 'Gender'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d9fe47f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'no'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_38716\\2005203351.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mbroad_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mbroad_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    323\u001b[0m         \"\"\"\n\u001b[0;32m    324\u001b[0m         \u001b[1;31m# Validate or convert input data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"sparse multilabel-indicator for y is not supported.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 327\u001b[1;33m         X, y = self._validate_data(\n\u001b[0m\u001b[0;32m    328\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m         )\n\u001b[0;32m    330\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    577\u001b[0m                 \u001b[0mcheck_X_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_y_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_separately\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m                 \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_X_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 581\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    582\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ensure_2d\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    960\u001b[0m     \"\"\"\n\u001b[0;32m    961\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y cannot be None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 964\u001b[1;33m     X = check_array(\n\u001b[0m\u001b[0;32m    965\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m         \u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    743\u001b[0m                         \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    744\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    745\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    746\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 747\u001b[1;33m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    748\u001b[0m                 raise ValueError(\n\u001b[0;32m    749\u001b[0m                     \u001b[1;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m                 ) from complex_warning\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1996\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1997\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1998\u001b[1;33m         \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1999\u001b[0m         if (\n\u001b[0;32m   2000\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2001\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'no'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X = df.drop(['WeightCategory','BroadCategory'], axis=1)\n",
    "y = df['BroadCategory']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "broad_model = RandomForestClassifier(random_state=42)\n",
    "broad_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13ebb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overweight subset\n",
    "over_df = df[df['BroadCategory'] == 'Overweight']\n",
    "X_over = over_df.drop(['WeightCategory','BroadCategory'], axis=1)\n",
    "y_over = over_df['WeightCategory']\n",
    "over_model = RandomForestClassifier(random_state=42).fit(X_over, y_over)\n",
    "\n",
    "# Obese subset\n",
    "obese_df = df[df['BroadCategory'] == 'Obese']\n",
    "X_ob = obese_df.drop(['WeightCategory','BroadCategory'], axis=1)\n",
    "y_ob = obese_df['WeightCategory']\n",
    "ob_model = RandomForestClassifier(random_state=42).fit(X_ob, y_ob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14b0e90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479e6ca5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b6ac22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f60bd59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be094f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "cat_cols = ['family_history_with_overweight', 'FAVC', 'CAEC', \n",
    "            'SMOKE', 'SCC', 'CALC', 'MTRANS']\n",
    "\n",
    "le = LabelEncoder()\n",
    "for col in cat_cols:\n",
    "    df[col] = le.fit_transform(df[col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce894e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "weight_order = CategoricalDtype(categories=order, ordered=True)\n",
    "df['WeightCategory'] = df['WeightCategory'].astype(weight_order)\n",
    "df['WeightCategory'] = df['WeightCategory'].cat.codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ffc346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78709b1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f87535c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa009d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e34febc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WeightCategory\n",
      "Insufficient_Weight     682\n",
      "Normal_Weight          1072\n",
      "Overweight_Level_I     1051\n",
      "Overweight_Level_II    1325\n",
      "Obesity_Type_I         1252\n",
      "Obesity_Type_II        2397\n",
      "Obesity_Type_III          4\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Ensure the WeightCategory column is categorical with the specified order\n",
    "df_male['WeightCategory'] = pd.Categorical(df_male['WeightCategory'], categories=order, ordered=True)\n",
    "\n",
    "# Get counts according to the specified order\n",
    "counts = df_male['WeightCategory'].value_counts().reindex(order)\n",
    "\n",
    "print(counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9216a74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d2cec0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fba285",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a829e56a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cb9246bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ MALE MODELS ------\n",
      "\n",
      "=== Stage 1 (Broad) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.86      0.86      0.86       215\n",
      "       Obese       0.98      0.97      0.97       731\n",
      "  Overweight       0.92      0.92      0.92       475\n",
      " Underweight       0.89      0.92      0.91       136\n",
      "\n",
      "    accuracy                           0.94      1557\n",
      "   macro avg       0.91      0.92      0.91      1557\n",
      "weighted avg       0.94      0.94      0.94      1557\n",
      "\n",
      "Broad Accuracy: 0.9351316634553629\n",
      "\n",
      "=== Stage 2 (Overweight: Level I vs II) ===\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      " Overweight_Level_I       1.00      1.00      1.00      1051\n",
      "Overweight_Level_II       1.00      1.00      1.00      1325\n",
      "\n",
      "           accuracy                           1.00      2376\n",
      "          macro avg       1.00      1.00      1.00      2376\n",
      "       weighted avg       1.00      1.00      1.00      2376\n",
      "\n",
      "\n",
      "=== Stage 2 (Obese: Type I/II/III) ===\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "  Obesity_Type_I       1.00      1.00      1.00      1252\n",
      " Obesity_Type_II       1.00      1.00      1.00      2397\n",
      "Obesity_Type_III       1.00      1.00      1.00         4\n",
      "\n",
      "        accuracy                           1.00      3653\n",
      "       macro avg       1.00      1.00      1.00      3653\n",
      "    weighted avg       1.00      1.00      1.00      3653\n",
      "\n",
      "\n",
      "\n",
      "------ FEMALE MODELS ------\n",
      "\n",
      "=== Stage 1 (Broad) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.87      0.89      0.88       255\n",
      "       Obese       0.97      0.98      0.98       788\n",
      "  Overweight       0.89      0.87      0.88       270\n",
      " Underweight       0.94      0.93      0.94       237\n",
      "\n",
      "    accuracy                           0.94      1550\n",
      "   macro avg       0.92      0.92      0.92      1550\n",
      "weighted avg       0.94      0.94      0.94      1550\n",
      "\n",
      "Broad Accuracy: 0.9387096774193548\n",
      "\n",
      "=== Stage 2 (Overweight: Level I vs II) ===\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      " Overweight_Level_I       1.00      1.00      1.00       793\n",
      "Overweight_Level_II       1.00      1.00      1.00       556\n",
      "\n",
      "           accuracy                           1.00      1349\n",
      "          macro avg       1.00      1.00      1.00      1349\n",
      "       weighted avg       1.00      1.00      1.00      1349\n",
      "\n",
      "\n",
      "=== Stage 2 (Obese: Type I/II/III) ===\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "  Obesity_Type_I       1.00      1.00      1.00       955\n",
      " Obesity_Type_II       1.00      1.00      1.00         6\n",
      "Obesity_Type_III       1.00      1.00      1.00      2979\n",
      "\n",
      "        accuracy                           1.00      3940\n",
      "       macro avg       1.00      1.00      1.00      3940\n",
      "    weighted avg       1.00      1.00      1.00      3940\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# -----------------------------\n",
    "# 0) Assumptions / Setup\n",
    "# -----------------------------\n",
    "# df = ...  # your dataframe\n",
    "# Columns you shared:\n",
    "# ['id','Gender','Age','Height','Weight','family_history_with_overweight','FAVC','FCVC','NCP','CAEC','SMOKE','CH2O','SCC','FAF','TUE','CALC','MTRANS','WeightCategory']\n",
    "\n",
    "ORDER = [\n",
    "    'Insufficient_Weight',\n",
    "    'Normal_Weight',\n",
    "    'Overweight_Level_I',\n",
    "    'Overweight_Level_II',\n",
    "    'Obesity_Type_I',\n",
    "    'Obesity_Type_II',\n",
    "    'Obesity_Type_III'\n",
    "]\n",
    "\n",
    "def to_broad(cat: str) -> str:\n",
    "    if cat == 'Insufficient_Weight':\n",
    "        return 'Underweight'\n",
    "    if cat == 'Normal_Weight':\n",
    "        return 'Normal'\n",
    "    if cat.startswith('Overweight'):\n",
    "        return 'Overweight'\n",
    "    return 'Obese'  # all Obesity_* go here\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Basic feature engineering\n",
    "# -----------------------------\n",
    "df = df.copy()\n",
    "\n",
    "# Create BMI safely\n",
    "# df['BMI'] = df['Weight'] / ((df['Height'] / 100.0)**2)\n",
    "\n",
    "# Broad category for Stage 1\n",
    "df['BroadCategory'] = df['WeightCategory'].apply(to_broad)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Split by gender (two separate model families)\n",
    "# -----------------------------\n",
    "def prepare_gender_df(df, gender_value):\n",
    "    gdf = df[df['Gender'] == gender_value].copy()\n",
    "    # Drop id and Gender from features\n",
    "    # Keep BMI; you may keep Height/Weight too if you like—here we keep them\n",
    "    # Target columns remain for later splits\n",
    "    return gdf\n",
    "\n",
    "male_df = prepare_gender_df(df, 'Male')\n",
    "female_df = prepare_gender_df(df, 'Female')\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Common preprocessing: encode categoricals via ColumnTransformer\n",
    "# -----------------------------\n",
    "# Numerical (already numeric):\n",
    "num_cols = ['Age', 'Height', 'Weight', 'BMI', 'FCVC', 'NCP', 'CH2O', 'FAF', 'TUE']\n",
    "\n",
    "# Categorical (strings/yes-no/etc):\n",
    "cat_cols = [\n",
    "    'family_history_with_overweight', 'FAVC', 'CAEC', 'SMOKE',\n",
    "    'SCC', 'CALC', 'MTRANS'\n",
    "]\n",
    "# Do NOT include 'Gender' here since we dropped it from each gender subset.\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse=False), cat_cols),\n",
    "        ('num', 'passthrough', num_cols),\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Build pipelines\n",
    "# -----------------------------\n",
    "# Stage 1: Broad (Underweight/Normal/Overweight/Obese)\n",
    "broad_clf = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=None,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "broad_pipe = Pipeline(steps=[\n",
    "    ('prep', preprocess),\n",
    "    ('clf', broad_clf)\n",
    "])\n",
    "\n",
    "# Stage 2 models:\n",
    "over_clf = RandomForestClassifier(n_estimators=300, n_jobs=-1, random_state=42)\n",
    "obese_clf = RandomForestClassifier(n_estimators=300, n_jobs=-1, random_state=42)\n",
    "\n",
    "over_pipe = Pipeline(steps=[\n",
    "    ('prep', preprocess),\n",
    "    ('clf', over_clf)\n",
    "])\n",
    "\n",
    "obese_pipe = Pipeline(steps=[\n",
    "    ('prep', preprocess),\n",
    "    ('clf', obese_clf)\n",
    "])\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Train / evaluate per gender\n",
    "# -----------------------------\n",
    "def train_hierarchical_for_gender(gdf, label_order=ORDER):\n",
    "    # TRAIN/TEST for Stage 1 (BroadCategory)\n",
    "    X = gdf.drop(columns=['id','Gender','WeightCategory','BroadCategory'], errors='ignore')\n",
    "    y_broad = gdf['BroadCategory']\n",
    "\n",
    "    # In case id/Gender were already removed above, errors='ignore' keeps it safe.\n",
    "    # Also ensure all required columns exist in X:\n",
    "    for c in (set(cat_cols + num_cols) - set(X.columns)):\n",
    "        raise ValueError(f\"Missing required feature column: {c}\")\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y_broad, test_size=0.2, stratify=y_broad, random_state=42\n",
    "    )\n",
    "\n",
    "    broad_pipe.fit(X_train, y_train)\n",
    "    y_pred_broad = broad_pipe.predict(X_test)\n",
    "    print(\"\\n=== Stage 1 (Broad) ===\")\n",
    "    print(classification_report(y_test, y_pred_broad))\n",
    "    print(\"Broad Accuracy:\", accuracy_score(y_test, y_pred_broad))\n",
    "\n",
    "    # TRAIN Stage 2: Overweight submodel (Level I vs II)\n",
    "    over_df = gdf[gdf['BroadCategory'] == 'Overweight'].copy()\n",
    "    X_over = over_df.drop(columns=['id','Gender','WeightCategory','BroadCategory'], errors='ignore')\n",
    "    y_over = over_df['WeightCategory']\n",
    "    if len(over_df) > 0 and y_over.nunique() > 1:\n",
    "        over_pipe.fit(X_over, y_over)\n",
    "        y_pred_over = over_pipe.predict(X_over)\n",
    "        print(\"\\n=== Stage 2 (Overweight: Level I vs II) ===\")\n",
    "        print(classification_report(y_over, y_pred_over, labels=['Overweight_Level_I','Overweight_Level_II']))\n",
    "    else:\n",
    "        print(\"\\n=== Stage 2 (Overweight) ===\")\n",
    "        print(\"Not enough variation to train (need both Level I and Level II).\")\n",
    "\n",
    "    # TRAIN Stage 2: Obese submodel (Type I/II/III)\n",
    "    obese_df = gdf[gdf['BroadCategory'] == 'Obese'].copy()\n",
    "    X_ob = obese_df.drop(columns=['id','Gender','WeightCategory','BroadCategory'], errors='ignore')\n",
    "    y_ob = obese_df['WeightCategory']\n",
    "    if len(obese_df) > 0 and y_ob.nunique() > 1:\n",
    "        obese_pipe.fit(X_ob, y_ob)\n",
    "        y_pred_ob = obese_pipe.predict(X_ob)\n",
    "        print(\"\\n=== Stage 2 (Obese: Type I/II/III) ===\")\n",
    "        # Reduce report to relevant classes present\n",
    "        present = [c for c in ['Obesity_Type_I','Obesity_Type_II','Obesity_Type_III'] if c in y_ob.unique()]\n",
    "        print(classification_report(y_ob, y_pred_ob, labels=present))\n",
    "    else:\n",
    "        print(\"\\n=== Stage 2 (Obese) ===\")\n",
    "        print(\"Not enough variation to train (need at least two Obesity types).\")\n",
    "\n",
    "    return broad_pipe, over_pipe, obese_pipe\n",
    "\n",
    "print(\"------ MALE MODELS ------\")\n",
    "male_broad, male_over, male_obese = train_hierarchical_for_gender(male_df)\n",
    "\n",
    "print(\"\\n\\n------ FEMALE MODELS ------\")\n",
    "female_broad, female_over, female_obese = train_hierarchical_for_gender(female_df)\n",
    "\n",
    "# -----------------------------\n",
    "# 6) Unified predict function\n",
    "# -----------------------------\n",
    "def predict_full(sample_df, broad_model, over_model, obese_model):\n",
    "    \"\"\"\n",
    "    sample_df: dataframe with SAME columns as training X (no id/Gender/targets),\n",
    "               and with raw categorical strings; the pipeline handles encoding.\n",
    "    \"\"\"\n",
    "    bpred = broad_model.predict(sample_df)[0]\n",
    "    if bpred == 'Overweight':\n",
    "        # If overweight sub-model wasn't trained, fall back to broad\n",
    "        try:\n",
    "            return over_model.predict(sample_df)[0]\n",
    "        except Exception:\n",
    "            return 'Overweight_Level_I'  # simple fallback\n",
    "    elif bpred == 'Obese':\n",
    "        try:\n",
    "            return obese_model.predict(sample_df)[0]\n",
    "        except Exception:\n",
    "            return 'Obesity_Type_I'  # simple fallback\n",
    "    else:\n",
    "        # Underweight or Normal are final\n",
    "        return 'Insufficient_Weight' if bpred == 'Underweight' else 'Normal_Weight'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf9ad52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca118e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e607f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eae06988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_hierarchical_for_gender(gdf, label_order=ORDER):\n",
    "    # --- Stage 1: Broad Category ---\n",
    "    X = gdf.drop(columns=['id', 'Gender', 'WeightCategory', 'BroadCategory'], errors='ignore')\n",
    "    y_broad = gdf['BroadCategory']\n",
    "\n",
    "    for c in (set(cat_cols + num_cols) - set(X.columns)):\n",
    "        raise ValueError(f\"Missing required feature column: {c}\")\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y_broad, test_size=0.2, stratify=y_broad, random_state=42\n",
    "    )\n",
    "\n",
    "    broad_pipe.fit(X_train, y_train)\n",
    "    y_pred_broad = broad_pipe.predict(X_test)\n",
    "    broad_acc = accuracy_score(y_test, y_pred_broad)\n",
    "    print(\"\\n=== Stage 1 (Broad) ===\")\n",
    "    print(classification_report(y_test, y_pred_broad))\n",
    "    print(\"Broad Accuracy:\", broad_acc)\n",
    "\n",
    "    # --- Stage 2: Overweight (Level I vs II) ---\n",
    "    over_df = gdf[gdf['BroadCategory'] == 'Overweight'].copy()\n",
    "    X_over = over_df.drop(columns=['id', 'Gender', 'WeightCategory', 'BroadCategory'], errors='ignore')\n",
    "    y_over = over_df['WeightCategory']\n",
    "    over_acc = None\n",
    "    if len(over_df) > 0 and y_over.nunique() > 1:\n",
    "        over_pipe.fit(X_over, y_over)\n",
    "        y_pred_over = over_pipe.predict(X_over)\n",
    "        over_acc = accuracy_score(y_over, y_pred_over)\n",
    "        print(\"\\n=== Stage 2 (Overweight: Level I vs II) ===\")\n",
    "        print(classification_report(y_over, y_pred_over, labels=['Overweight_Level_I', 'Overweight_Level_II']))\n",
    "        print(\"Overweight Accuracy:\", over_acc)\n",
    "    else:\n",
    "        print(\"\\n=== Stage 2 (Overweight) ===\")\n",
    "        print(\"Not enough variation to train (need both Level I and Level II).\")\n",
    "\n",
    "    # --- Stage 2: Obese (Type I / II / III) ---\n",
    "    obese_df = gdf[gdf['BroadCategory'] == 'Obese'].copy()\n",
    "    X_ob = obese_df.drop(columns=['id', 'Gender', 'WeightCategory', 'BroadCategory'], errors='ignore')\n",
    "    y_ob = obese_df['WeightCategory']\n",
    "    obese_acc = None\n",
    "    if len(obese_df) > 0 and y_ob.nunique() > 1:\n",
    "        obese_pipe.fit(X_ob, y_ob)\n",
    "        y_pred_ob = obese_pipe.predict(X_ob)\n",
    "        obese_acc = accuracy_score(y_ob, y_pred_ob)\n",
    "        present = [c for c in ['Obesity_Type_I', 'Obesity_Type_II', 'Obesity_Type_III'] if c in y_ob.unique()]\n",
    "        print(\"\\n=== Stage 2 (Obese: Type I/II/III) ===\")\n",
    "        print(classification_report(y_ob, y_pred_ob, labels=present))\n",
    "        print(\"Obese Accuracy:\", obese_acc)\n",
    "    else:\n",
    "        print(\"\\n=== Stage 2 (Obese) ===\")\n",
    "        print(\"Not enough variation to train (need at least two Obesity types).\")\n",
    "\n",
    "    # --- Return all models and metrics ---\n",
    "    return broad_pipe, over_pipe, obese_pipe, broad_acc, over_acc, obese_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e62ce15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ MALE MODELS ------\n",
      "\n",
      "=== Stage 1 (Broad) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.86      0.86      0.86       215\n",
      "       Obese       0.98      0.97      0.97       731\n",
      "  Overweight       0.92      0.92      0.92       475\n",
      " Underweight       0.89      0.92      0.91       136\n",
      "\n",
      "    accuracy                           0.94      1557\n",
      "   macro avg       0.91      0.92      0.91      1557\n",
      "weighted avg       0.94      0.94      0.94      1557\n",
      "\n",
      "Broad Accuracy: 0.9351316634553629\n",
      "\n",
      "=== Stage 2 (Overweight: Level I vs II) ===\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      " Overweight_Level_I       1.00      1.00      1.00      1051\n",
      "Overweight_Level_II       1.00      1.00      1.00      1325\n",
      "\n",
      "           accuracy                           1.00      2376\n",
      "          macro avg       1.00      1.00      1.00      2376\n",
      "       weighted avg       1.00      1.00      1.00      2376\n",
      "\n",
      "Overweight Accuracy: 1.0\n",
      "\n",
      "=== Stage 2 (Obese: Type I/II/III) ===\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "  Obesity_Type_I       1.00      1.00      1.00      1252\n",
      " Obesity_Type_II       1.00      1.00      1.00      2397\n",
      "Obesity_Type_III       1.00      1.00      1.00         4\n",
      "\n",
      "        accuracy                           1.00      3653\n",
      "       macro avg       1.00      1.00      1.00      3653\n",
      "    weighted avg       1.00      1.00      1.00      3653\n",
      "\n",
      "Obese Accuracy: 1.0\n",
      "\n",
      "\n",
      "------ FEMALE MODELS ------\n",
      "\n",
      "=== Stage 1 (Broad) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.87      0.89      0.88       255\n",
      "       Obese       0.97      0.98      0.98       788\n",
      "  Overweight       0.89      0.87      0.88       270\n",
      " Underweight       0.94      0.93      0.94       237\n",
      "\n",
      "    accuracy                           0.94      1550\n",
      "   macro avg       0.92      0.92      0.92      1550\n",
      "weighted avg       0.94      0.94      0.94      1550\n",
      "\n",
      "Broad Accuracy: 0.9387096774193548\n",
      "\n",
      "=== Stage 2 (Overweight: Level I vs II) ===\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      " Overweight_Level_I       1.00      1.00      1.00       793\n",
      "Overweight_Level_II       1.00      1.00      1.00       556\n",
      "\n",
      "           accuracy                           1.00      1349\n",
      "          macro avg       1.00      1.00      1.00      1349\n",
      "       weighted avg       1.00      1.00      1.00      1349\n",
      "\n",
      "Overweight Accuracy: 1.0\n",
      "\n",
      "=== Stage 2 (Obese: Type I/II/III) ===\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "  Obesity_Type_I       1.00      1.00      1.00       955\n",
      " Obesity_Type_II       1.00      1.00      1.00         6\n",
      "Obesity_Type_III       1.00      1.00      1.00      2979\n",
      "\n",
      "        accuracy                           1.00      3940\n",
      "       macro avg       1.00      1.00      1.00      3940\n",
      "    weighted avg       1.00      1.00      1.00      3940\n",
      "\n",
      "Obese Accuracy: 1.0\n",
      "\n",
      "=== Summary ===\n",
      "Male   -> Broad: 0.935, Over: 1.0, Obese: 1.0\n",
      "Female -> Broad: 0.939, Over: 1.0, Obese: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"------ MALE MODELS ------\")\n",
    "male_broad, male_over, male_obese, male_broad_acc, male_over_acc, male_obese_acc = \\\n",
    "    train_hierarchical_for_gender(male_df)\n",
    "\n",
    "print(\"\\n\\n------ FEMALE MODELS ------\")\n",
    "female_broad, female_over, female_obese, female_broad_acc, female_over_acc, female_obese_acc = \\\n",
    "    train_hierarchical_for_gender(female_df)\n",
    "\n",
    "print(\"\\n=== Summary ===\")\n",
    "print(f\"Male   -> Broad: {male_broad_acc:.3f}, Over: {male_over_acc}, Obese: {male_obese_acc}\")\n",
    "print(f\"Female -> Broad: {female_broad_acc:.3f}, Over: {female_over_acc}, Obese: {female_obese_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd351456",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5754617",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0314cb8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f491408f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "03f284fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "over_clf  = RandomForestClassifier(n_estimators=300, n_jobs=-1, random_state=42, class_weight='balanced')\n",
    "obese_clf = RandomForestClassifier(n_estimators=300, n_jobs=-1, random_state=42, class_weight='balanced')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "23743d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "def train_hierarchical_for_gender(gdf, label_order=ORDER):\n",
    "    # ---------- Stage 1: Broad ----------\n",
    "    X = gdf.drop(columns=['id','Gender','WeightCategory','BroadCategory'], errors='ignore')\n",
    "    y_broad = gdf['BroadCategory']\n",
    "\n",
    "    for c in (set(cat_cols + num_cols) - set(X.columns)):\n",
    "        raise ValueError(f\"Missing required feature column: {c}\")\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y_broad, test_size=0.2, stratify=y_broad, random_state=42\n",
    "    )\n",
    "\n",
    "    broad_pipe.fit(X_train, y_train)\n",
    "    y_pred_broad = broad_pipe.predict(X_test)\n",
    "    broad_acc = accuracy_score(y_test, y_pred_broad)\n",
    "    print(\"\\n=== Stage 1 (Broad) ===\")\n",
    "    print(classification_report(y_test, y_pred_broad))\n",
    "    print(\"Broad Accuracy:\", broad_acc)\n",
    "\n",
    "    # ---------- Stage 2: Overweight (Level I vs II) ----------\n",
    "    over_labels = ['Overweight_Level_I','Overweight_Level_II']\n",
    "    over_df = gdf[gdf['BroadCategory'] == 'Overweight'].copy()\n",
    "    over_df = over_df[over_df['WeightCategory'].isin(over_labels)]\n",
    "\n",
    "    over_acc = None\n",
    "    if len(over_df) > 0 and over_df['WeightCategory'].nunique() == 2:\n",
    "        X_over = over_df.drop(columns=['id','Gender','WeightCategory','BroadCategory'], errors='ignore')\n",
    "        y_over = over_df['WeightCategory']\n",
    "\n",
    "        Xo_tr, Xo_te, yo_tr, yo_te = train_test_split(\n",
    "            X_over, y_over, test_size=0.2, stratify=y_over, random_state=42\n",
    "        )\n",
    "        over_pipe.fit(Xo_tr, yo_tr)\n",
    "        yo_pred = over_pipe.predict(Xo_te)\n",
    "        over_acc = accuracy_score(yo_te, yo_pred)\n",
    "        print(\"\\n=== Stage 2 (Overweight: I vs II) ===\")\n",
    "        print(classification_report(yo_te, yo_pred, labels=over_labels, target_names=over_labels))\n",
    "        print(\"Overweight Accuracy:\", over_acc)\n",
    "    else:\n",
    "        print(\"\\n=== Stage 2 (Overweight) ===\")\n",
    "        print(\"Not enough variation to train (need both Level I and Level II).\")\n",
    "\n",
    "    # ---------- Stage 2: Obese (Type I / II / III) ----------\n",
    "    obese_labels = ['Obesity_Type_I','Obesity_Type_II','Obesity_Type_III']\n",
    "    obese_df = gdf[gdf['BroadCategory'] == 'Obese'].copy()\n",
    "    obese_df = obese_df[obese_df['WeightCategory'].isin(obese_labels)]\n",
    "\n",
    "    obese_acc = None\n",
    "    if len(obese_df) > 0 and obese_df['WeightCategory'].nunique() >= 2:\n",
    "        X_ob = obese_df.drop(columns=['id','Gender','WeightCategory','BroadCategory'], errors='ignore')\n",
    "        y_ob = obese_df['WeightCategory']\n",
    "\n",
    "        Xb_tr, Xb_te, yb_tr, yb_te = train_test_split(\n",
    "            X_ob, y_ob, test_size=0.2, stratify=y_ob, random_state=42\n",
    "        )\n",
    "        obese_pipe.fit(Xb_tr, yb_tr)\n",
    "        yb_pred = obese_pipe.predict(Xb_te)\n",
    "        # use only the labels present in yb_te to avoid warnings on tiny classes\n",
    "        present = [c for c in obese_labels if c in yb_te.unique()]\n",
    "        obese_acc = accuracy_score(yb_te, yb_pred)\n",
    "        print(\"\\n=== Stage 2 (Obese: Type I/II/III) ===\")\n",
    "        print(classification_report(yb_te, yb_pred, labels=present, target_names=present))\n",
    "        print(\"Obese Accuracy:\", obese_acc)\n",
    "    else:\n",
    "        print(\"\\n=== Stage 2 (Obese) ===\")\n",
    "        print(\"Not enough variation to train (need at least two Obesity types).\")\n",
    "\n",
    "    return broad_pipe, over_pipe, obese_pipe, broad_acc, over_acc, obese_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a1620ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ MALE MODELS ------\n",
      "\n",
      "=== Stage 1 (Broad) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.86      0.86      0.86       215\n",
      "       Obese       0.98      0.97      0.97       731\n",
      "  Overweight       0.92      0.92      0.92       475\n",
      " Underweight       0.89      0.92      0.91       136\n",
      "\n",
      "    accuracy                           0.94      1557\n",
      "   macro avg       0.91      0.92      0.91      1557\n",
      "weighted avg       0.94      0.94      0.94      1557\n",
      "\n",
      "Broad Accuracy: 0.9351316634553629\n",
      "\n",
      "=== Stage 2 (Overweight: I vs II) ===\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      " Overweight_Level_I       0.91      0.86      0.88       211\n",
      "Overweight_Level_II       0.89      0.93      0.91       265\n",
      "\n",
      "           accuracy                           0.90       476\n",
      "          macro avg       0.90      0.90      0.90       476\n",
      "       weighted avg       0.90      0.90      0.90       476\n",
      "\n",
      "Overweight Accuracy: 0.8991596638655462\n",
      "\n",
      "=== Stage 2 (Obese: Type I/II/III) ===\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "  Obesity_Type_I       0.95      0.92      0.94       250\n",
      " Obesity_Type_II       0.96      0.97      0.97       480\n",
      "Obesity_Type_III       0.00      0.00      0.00         1\n",
      "\n",
      "        accuracy                           0.95       731\n",
      "       macro avg       0.64      0.63      0.63       731\n",
      "    weighted avg       0.95      0.95      0.95       731\n",
      "\n",
      "Obese Accuracy: 0.9548563611491108\n",
      "\n",
      "\n",
      "------ FEMALE MODELS ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\surya\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\surya\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\surya\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Stage 1 (Broad) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.87      0.89      0.88       255\n",
      "       Obese       0.97      0.98      0.98       788\n",
      "  Overweight       0.89      0.87      0.88       270\n",
      " Underweight       0.94      0.93      0.94       237\n",
      "\n",
      "    accuracy                           0.94      1550\n",
      "   macro avg       0.92      0.92      0.92      1550\n",
      "weighted avg       0.94      0.94      0.94      1550\n",
      "\n",
      "Broad Accuracy: 0.9387096774193548\n",
      "\n",
      "=== Stage 2 (Overweight: I vs II) ===\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      " Overweight_Level_I       0.92      0.84      0.88       159\n",
      "Overweight_Level_II       0.79      0.89      0.84       111\n",
      "\n",
      "           accuracy                           0.86       270\n",
      "          macro avg       0.85      0.86      0.86       270\n",
      "       weighted avg       0.87      0.86      0.86       270\n",
      "\n",
      "Overweight Accuracy: 0.8592592592592593\n",
      "\n",
      "=== Stage 2 (Obese: Type I/II/III) ===\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "  Obesity_Type_I       0.99      0.98      0.99       191\n",
      " Obesity_Type_II       0.00      0.00      0.00         1\n",
      "Obesity_Type_III       0.99      1.00      1.00       596\n",
      "\n",
      "        accuracy                           0.99       788\n",
      "       macro avg       0.66      0.66      0.66       788\n",
      "    weighted avg       0.99      0.99      0.99       788\n",
      "\n",
      "Obese Accuracy: 0.9949238578680203\n",
      "\n",
      "=== Summary ===\n",
      "Model Type | Broad Acc  | Overweight Acc  | Obesity Acc\n",
      "------------------------------------------------------------\n",
      "Male       | 0.935      | 0.899           | 0.955\n",
      "Female     | 0.939      | 0.859           | 0.995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\surya\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\surya\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\surya\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"------ MALE MODELS ------\")\n",
    "male_broad, male_over, male_obese, male_broad_acc, male_over_acc, male_obese_acc = \\\n",
    "    train_hierarchical_for_gender(male_df)\n",
    "\n",
    "print(\"\\n\\n------ FEMALE MODELS ------\")\n",
    "female_broad, female_over, female_obese, female_broad_acc, female_over_acc, female_obese_acc = \\\n",
    "    train_hierarchical_for_gender(female_df)\n",
    "\n",
    "# -----------------------------\n",
    "# SUMMARY COMPARISON\n",
    "# -----------------------------\n",
    "print(\"\\n=== Summary ===\")\n",
    "print(f\"{'Model Type':<10} | {'Broad Acc':<10} | {'Overweight Acc':<15} | {'Obesity Acc'}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Male':<10} | {male_broad_acc:.3f}{'':<5} | {str(round(male_over_acc,3)) if male_over_acc else 'N/A':<15} | {str(round(male_obese_acc,3)) if male_obese_acc else 'N/A'}\")\n",
    "print(f\"{'Female':<10} | {female_broad_acc:.3f}{'':<5} | {str(round(female_over_acc,3)) if female_over_acc else 'N/A':<15} | {str(round(female_obese_acc,3)) if female_obese_acc else 'N/A'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "308ddb68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'Gender', 'Age', 'Height', 'Weight',\n",
       "       'family_history_with_overweight', 'FAVC', 'FCVC', 'NCP', 'CAEC',\n",
       "       'SMOKE', 'CH2O', 'SCC', 'FAF', 'TUE', 'CALC', 'MTRANS',\n",
       "       'WeightCategory', 'BroadCategory', 'BMI'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d57df6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2460b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6bd6833d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b1b6599b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'Gender', 'Age', 'Height', 'Weight',\n",
       "       'family_history_with_overweight', 'FAVC', 'FCVC', 'NCP', 'CAEC',\n",
       "       'SMOKE', 'CH2O', 'SCC', 'FAF', 'TUE', 'CALC', 'MTRANS', 'BMI'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41e57db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9c154ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['BMI'] = test['Weight'] / (test['Height'] ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "28f54947",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = [\n",
    "    # categorical\n",
    "    'family_history_with_overweight','FAVC','CAEC','SMOKE','SCC','CALC','MTRANS',\n",
    "    # numeric\n",
    "    'Age','Height','Weight','BMI','FCVC','NCP','CH2O','FAF','TUE'\n",
    "]\n",
    "\n",
    "def build_inference_sample(row):\n",
    "    s = row.to_frame().T.copy()\n",
    "\n",
    "    # If your Height is in cm, compute BMI as Weight / ( (Height_cm/100)^2 )\n",
    "    # You currently do Weight/(Height**2). Keep it only if Height is already in meters.\n",
    "    # s['BMI'] = s['Weight'] / ((s['Height']/100.0)**2)  # uncomment if Height is cm\n",
    "\n",
    "    # Ensure CH2O is present (fix common CH20 typo)\n",
    "    if 'CH20' in s.columns and 'CH2O' not in s.columns:\n",
    "        s['CH2O'] = s['CH20']\n",
    "\n",
    "    # Keep ONLY model features in the exact order\n",
    "    s = s.reindex(columns=FEATURES)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ad15a50e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 27 features, but RandomForestClassifier is expecting 29 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m     pred \u001b[38;5;241m=\u001b[39m predict_full(sample, male_broad, male_over, male_obese)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 10\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_full\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfemale_broad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfemale_over\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfemale_obese\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m predictions\u001b[38;5;241m.\u001b[39mappend((row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m], pred))\n",
      "Cell \u001b[1;32mIn[41], line 179\u001b[0m, in \u001b[0;36mpredict_full\u001b[1;34m(sample_df, broad_model, over_model, obese_model)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_full\u001b[39m(sample_df, broad_model, over_model, obese_model):\n\u001b[0;32m    175\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;124;03m    sample_df: dataframe with SAME columns as training X (no id/Gender/targets),\u001b[39;00m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;124;03m               and with raw categorical strings; the pipeline handles encoding.\u001b[39;00m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 179\u001b[0m     bpred \u001b[38;5;241m=\u001b[39m \u001b[43mbroad_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_df\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bpred \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOverweight\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    181\u001b[0m         \u001b[38;5;66;03m# If overweight sub-model wasn't trained, fall back to broad\u001b[39;00m\n\u001b[0;32m    182\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\metaestimators.py:113\u001b[0m, in \u001b[0;36m_AvailableIfDescriptor.__get__.<locals>.<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m attr_err\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;66;03m# lambda, but not partial, allows help() to work with update_wrapper\u001b[39;00m\n\u001b[1;32m--> 113\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn(obj, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\pipeline.py:470\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[1;34m(self, X, **predict_params)\u001b[0m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(with_final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    469\u001b[0m     Xt \u001b[38;5;241m=\u001b[39m transform\u001b[38;5;241m.\u001b[39mtransform(Xt)\n\u001b[1;32m--> 470\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpredict(Xt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpredict_params)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:808\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    788\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    789\u001b[0m \u001b[38;5;124;03m    Predict class for X.\u001b[39;00m\n\u001b[0;32m    790\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    806\u001b[0m \u001b[38;5;124;03m        The predicted classes.\u001b[39;00m\n\u001b[0;32m    807\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 808\u001b[0m     proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    810\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    811\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39margmax(proba, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:850\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    848\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    849\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[1;32m--> 850\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_X_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m    853\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:579\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;124;03mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[0;32m    578\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 579\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[0;32m    581\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:585\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    582\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 585\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    587\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:400\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 400\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    401\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    402\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    403\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 27 features, but RandomForestClassifier is expecting 29 features as input."
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "\n",
    "for _, row in test.iterrows():\n",
    "    sample = build_inference_sample(row)\n",
    "\n",
    "    # Route based on gender (use the correct model set)\n",
    "    if row['Gender'] == 'Male':\n",
    "        pred = predict_full(sample, male_broad, male_over, male_obese)\n",
    "    else:\n",
    "        pred = predict_full(sample, female_broad, female_over, female_obese)\n",
    "\n",
    "    predictions.append((row['id'], pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797250a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = pd.DataFrame(predictions, columns=['id', 'WeightCategory'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
