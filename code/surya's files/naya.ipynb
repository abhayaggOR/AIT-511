{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfe3c610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2532ea63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e2116e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "order = [\n",
    "    'Insufficient_Weight',\n",
    "    'Normal_Weight',\n",
    "    'Overweight_Level_I',\n",
    "    'Overweight_Level_II',\n",
    "    'Obesity_Type_I',\n",
    "    'Obesity_Type_II',\n",
    "    'Obesity_Type_III'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6014408",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# -----------------------------\n",
    "# 0) Assumptions / Setup\n",
    "# -----------------------------\n",
    "# df = ...  # your dataframe\n",
    "# Columns you shared:\n",
    "# ['id','Gender','Age','Height','Weight','family_history_with_overweight','FAVC','FCVC','NCP','CAEC','SMOKE','CH2O','SCC','FAF','TUE','CALC','MTRANS','WeightCategory']\n",
    "\n",
    "ORDER = [\n",
    "    'Insufficient_Weight',\n",
    "    'Normal_Weight',\n",
    "    'Overweight_Level_I',\n",
    "    'Overweight_Level_II',\n",
    "    'Obesity_Type_I',\n",
    "    'Obesity_Type_II',\n",
    "    'Obesity_Type_III'\n",
    "]\n",
    "\n",
    "def to_broad(cat: str) -> str:\n",
    "    if cat == 'Insufficient_Weight':\n",
    "        return 'Underweight'\n",
    "    if cat == 'Normal_Weight':\n",
    "        return 'Normal'\n",
    "    if cat.startswith('Overweight'):\n",
    "        return 'Overweight'\n",
    "    return 'Obese'  # all Obesity_* go here\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Basic feature engineering\n",
    "# -----------------------------\n",
    "df = df.copy()\n",
    "\n",
    "# Create BMI safely\n",
    "# df['BMI'] = df['Weight'] / ((df['Height'] / 100.0)**2)\n",
    "df['BMI'] = df['Weight'] / (df['Height'] ** 2)\n",
    "\n",
    "# Broad category for Stage 1\n",
    "df['BroadCategory'] = df['WeightCategory'].apply(to_broad)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Split by gender (two separate model families)\n",
    "# -----------------------------\n",
    "def prepare_gender_df(df, gender_value):\n",
    "    gdf = df[df['Gender'] == gender_value].copy()\n",
    "    # Drop id and Gender from features\n",
    "    # Keep BMI; you may keep Height/Weight too if you like—here we keep them\n",
    "    # Target columns remain for later splits\n",
    "    return gdf\n",
    "\n",
    "male_df = prepare_gender_df(df, 'Male')\n",
    "female_df = prepare_gender_df(df, 'Female')\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Common preprocessing: encode categoricals via ColumnTransformer\n",
    "# -----------------------------\n",
    "# Numerical (already numeric):\n",
    "num_cols = ['Age', 'Height', 'Weight', 'BMI', 'FCVC', 'NCP', 'CH2O', 'FAF', 'TUE']\n",
    "\n",
    "# Categorical (strings/yes-no/etc):\n",
    "cat_cols = [\n",
    "    'family_history_with_overweight', 'FAVC', 'CAEC', 'SMOKE',\n",
    "    'SCC', 'CALC', 'MTRANS'\n",
    "]\n",
    "# Do NOT include 'Gender' here since we dropped it from each gender subset.\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse=False), cat_cols),\n",
    "        ('num', 'passthrough', num_cols),\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Build pipelines\n",
    "# -----------------------------\n",
    "# Stage 1: Broad (Underweight/Normal/Overweight/Obese)\n",
    "broad_clf = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=None,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "broad_pipe = Pipeline(steps=[\n",
    "    ('prep', preprocess),\n",
    "    ('clf', broad_clf)\n",
    "])\n",
    "\n",
    "# Stage 2 models:\n",
    "over_clf = RandomForestClassifier(n_estimators=300, n_jobs=-1, random_state=42)\n",
    "obese_clf = RandomForestClassifier(n_estimators=300, n_jobs=-1, random_state=42)\n",
    "\n",
    "over_pipe = Pipeline(steps=[\n",
    "    ('prep', preprocess),\n",
    "    ('clf', over_clf)\n",
    "])\n",
    "\n",
    "obese_pipe = Pipeline(steps=[\n",
    "    ('prep', preprocess),\n",
    "    ('clf', obese_clf)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "564a3db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_hierarchical_for_gender(gdf, label_order=ORDER):\n",
    "    # --- Stage 1: Broad Category ---\n",
    "    X = gdf.drop(columns=['id', 'Gender', 'WeightCategory', 'BroadCategory'], errors='ignore')\n",
    "    y_broad = gdf['BroadCategory']\n",
    "\n",
    "    for c in (set(cat_cols + num_cols) - set(X.columns)):\n",
    "        raise ValueError(f\"Missing required feature column: {c}\")\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y_broad, test_size=0.2, stratify=y_broad, random_state=42\n",
    "    )\n",
    "\n",
    "    broad_pipe.fit(X_train, y_train)\n",
    "    y_pred_broad = broad_pipe.predict(X_test)\n",
    "    broad_acc = accuracy_score(y_test, y_pred_broad)\n",
    "    print(\"\\n=== Stage 1 (Broad) ===\")\n",
    "    print(classification_report(y_test, y_pred_broad))\n",
    "    print(\"Broad Accuracy:\", broad_acc)\n",
    "\n",
    "    # --- Stage 2: Overweight (Level I vs II) ---\n",
    "    over_df = gdf[gdf['BroadCategory'] == 'Overweight'].copy()\n",
    "    X_over = over_df.drop(columns=['id', 'Gender', 'WeightCategory', 'BroadCategory'], errors='ignore')\n",
    "    y_over = over_df['WeightCategory']\n",
    "    over_acc = None\n",
    "    if len(over_df) > 0 and y_over.nunique() > 1:\n",
    "        over_pipe.fit(X_over, y_over)\n",
    "        y_pred_over = over_pipe.predict(X_over)\n",
    "        over_acc = accuracy_score(y_over, y_pred_over)\n",
    "        print(\"\\n=== Stage 2 (Overweight: Level I vs II) ===\")\n",
    "        print(classification_report(y_over, y_pred_over, labels=['Overweight_Level_I', 'Overweight_Level_II']))\n",
    "        print(\"Overweight Accuracy:\", over_acc)\n",
    "    else:\n",
    "        print(\"\\n=== Stage 2 (Overweight) ===\")\n",
    "        print(\"Not enough variation to train (need both Level I and Level II).\")\n",
    "\n",
    "    # --- Stage 2: Obese (Type I / II / III) ---\n",
    "    obese_df = gdf[gdf['BroadCategory'] == 'Obese'].copy()\n",
    "    X_ob = obese_df.drop(columns=['id', 'Gender', 'WeightCategory', 'BroadCategory'], errors='ignore')\n",
    "    y_ob = obese_df['WeightCategory']\n",
    "    obese_acc = None\n",
    "    if len(obese_df) > 0 and y_ob.nunique() > 1:\n",
    "        obese_pipe.fit(X_ob, y_ob)\n",
    "        y_pred_ob = obese_pipe.predict(X_ob)\n",
    "        obese_acc = accuracy_score(y_ob, y_pred_ob)\n",
    "        present = [c for c in ['Obesity_Type_I', 'Obesity_Type_II', 'Obesity_Type_III'] if c in y_ob.unique()]\n",
    "        print(\"\\n=== Stage 2 (Obese: Type I/II/III) ===\")\n",
    "        print(classification_report(y_ob, y_pred_ob, labels=present))\n",
    "        print(\"Obese Accuracy:\", obese_acc)\n",
    "    else:\n",
    "        print(\"\\n=== Stage 2 (Obese) ===\")\n",
    "        print(\"Not enough variation to train (need at least two Obesity types).\")\n",
    "\n",
    "    # --- Return all models and metrics ---\n",
    "    return broad_pipe, over_pipe, obese_pipe, broad_acc, over_acc, obese_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9ed9a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ MALE MODELS ------\n",
      "\n",
      "=== Stage 1 (Broad) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.86      0.86      0.86       215\n",
      "       Obese       0.98      0.97      0.97       731\n",
      "  Overweight       0.92      0.92      0.92       475\n",
      " Underweight       0.89      0.92      0.91       136\n",
      "\n",
      "    accuracy                           0.94      1557\n",
      "   macro avg       0.91      0.92      0.91      1557\n",
      "weighted avg       0.94      0.94      0.94      1557\n",
      "\n",
      "Broad Accuracy: 0.9351316634553629\n",
      "\n",
      "=== Stage 2 (Overweight: Level I vs II) ===\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      " Overweight_Level_I       1.00      1.00      1.00      1051\n",
      "Overweight_Level_II       1.00      1.00      1.00      1325\n",
      "\n",
      "           accuracy                           1.00      2376\n",
      "          macro avg       1.00      1.00      1.00      2376\n",
      "       weighted avg       1.00      1.00      1.00      2376\n",
      "\n",
      "Overweight Accuracy: 1.0\n",
      "\n",
      "=== Stage 2 (Obese: Type I/II/III) ===\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "  Obesity_Type_I       1.00      1.00      1.00      1252\n",
      " Obesity_Type_II       1.00      1.00      1.00      2397\n",
      "Obesity_Type_III       1.00      1.00      1.00         4\n",
      "\n",
      "        accuracy                           1.00      3653\n",
      "       macro avg       1.00      1.00      1.00      3653\n",
      "    weighted avg       1.00      1.00      1.00      3653\n",
      "\n",
      "Obese Accuracy: 1.0\n",
      "\n",
      "\n",
      "------ FEMALE MODELS ------\n",
      "\n",
      "=== Stage 1 (Broad) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.87      0.89      0.88       255\n",
      "       Obese       0.97      0.98      0.98       788\n",
      "  Overweight       0.89      0.87      0.88       270\n",
      " Underweight       0.94      0.93      0.94       237\n",
      "\n",
      "    accuracy                           0.94      1550\n",
      "   macro avg       0.92      0.92      0.92      1550\n",
      "weighted avg       0.94      0.94      0.94      1550\n",
      "\n",
      "Broad Accuracy: 0.9387096774193548\n",
      "\n",
      "=== Stage 2 (Overweight: Level I vs II) ===\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      " Overweight_Level_I       1.00      1.00      1.00       793\n",
      "Overweight_Level_II       1.00      1.00      1.00       556\n",
      "\n",
      "           accuracy                           1.00      1349\n",
      "          macro avg       1.00      1.00      1.00      1349\n",
      "       weighted avg       1.00      1.00      1.00      1349\n",
      "\n",
      "Overweight Accuracy: 1.0\n",
      "\n",
      "=== Stage 2 (Obese: Type I/II/III) ===\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "  Obesity_Type_I       1.00      1.00      1.00       955\n",
      " Obesity_Type_II       1.00      1.00      1.00         6\n",
      "Obesity_Type_III       1.00      1.00      1.00      2979\n",
      "\n",
      "        accuracy                           1.00      3940\n",
      "       macro avg       1.00      1.00      1.00      3940\n",
      "    weighted avg       1.00      1.00      1.00      3940\n",
      "\n",
      "Obese Accuracy: 1.0\n",
      "\n",
      "=== Summary ===\n",
      "Male   -> Broad: 0.935, Over: 1.0, Obese: 1.0\n",
      "Female -> Broad: 0.939, Over: 1.0, Obese: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"------ MALE MODELS ------\")\n",
    "male_broad, male_over, male_obese, male_broad_acc, male_over_acc, male_obese_acc = \\\n",
    "    train_hierarchical_for_gender(male_df)\n",
    "\n",
    "print(\"\\n\\n------ FEMALE MODELS ------\")\n",
    "female_broad, female_over, female_obese, female_broad_acc, female_over_acc, female_obese_acc = \\\n",
    "    train_hierarchical_for_gender(female_df)\n",
    "\n",
    "print(\"\\n=== Summary ===\")\n",
    "print(f\"Male   -> Broad: {male_broad_acc:.3f}, Over: {male_over_acc}, Obese: {male_obese_acc}\")\n",
    "print(f\"Female -> Broad: {female_broad_acc:.3f}, Over: {female_over_acc}, Obese: {female_obese_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66c80fb6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 27 features, but RandomForestClassifier is expecting 29 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 65\u001b[0m\n\u001b[0;32m     62\u001b[0m female_test \u001b[38;5;241m=\u001b[39m test[test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGender\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFemale\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Predict for both genders\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m male_pred \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_for_gender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmale_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmale_broad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmale_over\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmale_obese\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m female_pred \u001b[38;5;241m=\u001b[39m predict_for_gender(female_test, female_broad, female_over, female_obese)\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# Combine results\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[14], line 32\u001b[0m, in \u001b[0;36mpredict_for_gender\u001b[1;34m(test_part, broad_model, over_model, obese_model)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Predict for a gender-specific test subset.\"\"\"\u001b[39;00m\n\u001b[0;32m     31\u001b[0m X \u001b[38;5;241m=\u001b[39m build_feature_frame(test_part)\n\u001b[1;32m---> 32\u001b[0m broad_pred \u001b[38;5;241m=\u001b[39m \u001b[43mbroad_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m final_pred \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(broad_pred, index\u001b[38;5;241m=\u001b[39mtest_part\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Overweight subset → Level I vs II\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\metaestimators.py:113\u001b[0m, in \u001b[0;36m_AvailableIfDescriptor.__get__.<locals>.<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m attr_err\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;66;03m# lambda, but not partial, allows help() to work with update_wrapper\u001b[39;00m\n\u001b[1;32m--> 113\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn(obj, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\pipeline.py:470\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[1;34m(self, X, **predict_params)\u001b[0m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(with_final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    469\u001b[0m     Xt \u001b[38;5;241m=\u001b[39m transform\u001b[38;5;241m.\u001b[39mtransform(Xt)\n\u001b[1;32m--> 470\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpredict(Xt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpredict_params)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:808\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    788\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    789\u001b[0m \u001b[38;5;124;03m    Predict class for X.\u001b[39;00m\n\u001b[0;32m    790\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    806\u001b[0m \u001b[38;5;124;03m        The predicted classes.\u001b[39;00m\n\u001b[0;32m    807\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 808\u001b[0m     proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    810\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    811\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39margmax(proba, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:850\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    848\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    849\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[1;32m--> 850\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_X_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m    853\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:579\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;124;03mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[0;32m    578\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 579\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[0;32m    581\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:585\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    582\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 585\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    587\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:400\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 400\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    401\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    402\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    403\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 27 features, but RandomForestClassifier is expecting 29 features as input."
     ]
    }
   ],
   "source": [
    "# ========================\n",
    "# 🔹 MAKE PREDICTIONS ON TEST\n",
    "# ========================\n",
    "\n",
    "# Load test data\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# Compute BMI (same formula you used in training)\n",
    "# ⚠️ If your Height column is in cm, use (Height / 100)**2 instead.\n",
    "test['BMI'] = test['Weight'] / (test['Height'] ** 2)\n",
    "\n",
    "# Ensure same features\n",
    "cat_cols = [\n",
    "    'family_history_with_overweight', 'FAVC', 'CAEC', 'SMOKE',\n",
    "    'SCC', 'CALC', 'MTRANS'\n",
    "]\n",
    "num_cols = ['Age', 'Height', 'Weight', 'BMI', 'FCVC', 'NCP', 'CH2O', 'FAF', 'TUE']\n",
    "FEATURES = cat_cols + num_cols\n",
    "\n",
    "def build_feature_frame(df_like):\n",
    "    \"\"\"Ensure consistent feature columns and datatypes.\"\"\"\n",
    "    X = df_like.reindex(columns=FEATURES, fill_value=np.nan).copy()\n",
    "    for c in cat_cols:\n",
    "        X[c] = X[c].astype('object')\n",
    "    for c in num_cols:\n",
    "        X[c] = pd.to_numeric(X[c], errors='coerce')\n",
    "    return X\n",
    "\n",
    "def predict_for_gender(test_part, broad_model, over_model, obese_model):\n",
    "    \"\"\"Predict for a gender-specific test subset.\"\"\"\n",
    "    X = build_feature_frame(test_part)\n",
    "    broad_pred = broad_model.predict(X)\n",
    "\n",
    "    final_pred = pd.Series(broad_pred, index=test_part.index)\n",
    "\n",
    "    # Overweight subset → Level I vs II\n",
    "    over_idx = final_pred[final_pred == 'Overweight'].index\n",
    "    if len(over_idx) > 0:\n",
    "        try:\n",
    "            final_pred.loc[over_idx] = over_model.predict(X.loc[over_idx])\n",
    "        except Exception:\n",
    "            final_pred.loc[over_idx] = 'Overweight_Level_I'\n",
    "\n",
    "    # Obese subset → Type I/II/III\n",
    "    obese_idx = final_pred[final_pred == 'Obese'].index\n",
    "    if len(obese_idx) > 0:\n",
    "        try:\n",
    "            final_pred.loc[obese_idx] = obese_model.predict(X.loc[obese_idx])\n",
    "        except Exception:\n",
    "            final_pred.loc[obese_idx] = 'Obesity_Type_I'\n",
    "\n",
    "    # Map Underweight/Normal\n",
    "    final_pred = final_pred.replace({\n",
    "        'Underweight': 'Insufficient_Weight',\n",
    "        'Normal': 'Normal_Weight'\n",
    "    })\n",
    "\n",
    "    return final_pred\n",
    "\n",
    "# Split test set by gender\n",
    "male_test = test[test['Gender'] == 'Male']\n",
    "female_test = test[test['Gender'] == 'Female']\n",
    "\n",
    "# Predict for both genders\n",
    "male_pred = predict_for_gender(male_test, male_broad, male_over, male_obese)\n",
    "female_pred = predict_for_gender(female_test, female_broad, female_over, female_obese)\n",
    "\n",
    "# Combine results\n",
    "all_pred = pd.concat([male_pred, female_pred]).sort_index()\n",
    "\n",
    "# Build submission DataFrame\n",
    "submission = pd.DataFrame({\n",
    "    'id': test['id'],\n",
    "    'WeightCategory': all_pred.values\n",
    "})\n",
    "\n",
    "# Save submission file\n",
    "submission.to_csv('sample_submission.csv', index=False)\n",
    "print(submission.head(), '\\nSaved as sample_submission.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea525aec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
